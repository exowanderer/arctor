{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cQ0H-RyAp_2T"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1o7Q6X8TCXnt"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qpt0amocp_2X"
   },
   "outputs": [],
   "source": [
    "%run notebook_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j-ZULzpx60SU"
   },
   "source": [
    "# Load data in from Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kJOWjvPFCj2M"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_2LRtWCAp_2Z"
   },
   "source": [
    "# Transit fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oRQyaGBOp_2a"
   },
   "source": [
    "*exoplanet* includes methods for computing the light curves transiting planets.\n",
    "In its simplest form this can be used to evaluate a light curve like you would do with [batman](https://astro.uchicago.edu/~kreidberg/batman/), for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "HOME = os.environ['HOME']\n",
    "os.chdir(f'{HOME}/path/to/notebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nEjzyJgip_2a"
   },
   "outputs": [],
   "source": [
    "import exoplanet as xo\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "\n",
    "from exomast_api import exoMAST_API\n",
    "from statsmodels.robust.scale import mad\n",
    "from time import time\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from arctor import create_raw_lc_stddev, Arctor, run_multiple_pymc3#, setup_and_plot_GTC\n",
    "from arctor.utils import setup_and_plot_GTC, compute_delta_sdnr\n",
    "# from arctor.utils import fit_2D_time_vs_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_message(message, end='\\n'):\n",
    "    print(f'[DEBUG] {message}', end=end)\n",
    "\n",
    "\n",
    "def warning_message(message, end='\\n'):\n",
    "    print(f'[WARNING] {message}', end=end)\n",
    "\n",
    "\n",
    "def info_message(message, end='\\n'):\n",
    "    print(f'[INFO] {message}', end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GWd1PNSXDWWa"
   },
   "outputs": [],
   "source": [
    "plot_verbose = False\n",
    "save_now = False\n",
    "planet_name = 'PlanetName'\n",
    "file_type = 'flt.fits'\n",
    "\n",
    "HOME = os.environ['HOME']\n",
    "base_dir = os.path.join(HOME, 'path', 'to', 'base', 'dir)\n",
    "data_dir = os.path.join(base_dir, 'path', 'to', 'files')\n",
    "data_dir = os.path.join(data_dir, 'HST', 'FLTs')\n",
    "working_dir = os.path.join(base_dir, 'path', 'to', 'savefiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planet = Arctor(planet_name, data_dir, working_dir, file_type)\n",
    "joblib_filename = f'{planet_name}_savedict_206ppm_100x100_finescale.joblib.save'\n",
    "save_dir = f'{HOME}/path/to/savefiles'\n",
    "joblib_filename = f'{save_dir}/{joblib_filename}'\n",
    "planet.load_dict(joblib_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planet.photometry_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not hasattr(planet, 'photometry_df'):\n",
    "    # planet.load_dict(joblib_filename)\n",
    "    planet.clean_cosmic_rays()\n",
    "    planet.calibration_trace_location()\n",
    "    planet.identify_trace_direction()\n",
    "    planet.simple_phots()\n",
    "    planet.center_all_traces()\n",
    "    planet.fit_trace_slopes()\n",
    "    planet.compute_sky_background(subpixels=32)\n",
    "    planet.compute_columnwise_sky_background()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Multi-Phot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not hasattr(planet, 'photometry_df'):\n",
    "    # Set up the list of aperture widths and heights to search\n",
    "    min_aper_width = 1\n",
    "    max_aper_width = 100\n",
    "    min_aper_height = 1\n",
    "    max_aper_height = 100\n",
    "\n",
    "    aper_widths = np.arange(min_aper_width, max_aper_width + 2, 5)\n",
    "    aper_heights = np.arange(min_aper_height, max_aper_height + 2, 5)\n",
    "    \n",
    "    planet.do_multi_phot(aper_widths, aper_heights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine the 'best' photometry SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_photometry_df = np.median(planet.photometry_df, axis=0)\n",
    "planet.normed_photometry_df = planet.photometry_df / med_photometry_df\n",
    "planet.normed_uncertainty_df = np.sqrt(planet.photometry_df) / med_photometry_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planet_fine_photometry_df = planet.photometry_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_snr_lightcurves = create_raw_lc_stddev(planet)\n",
    "fine_min_snr = fine_snr_lightcurves[fine_snr_lightcurves.argmin()]\n",
    "fine_min_snr_colname = planet.photometry_df.columns[fine_snr_lightcurves.argmin()]\n",
    "fine_min_snr_flux = planet.normed_photometry_df[fine_min_snr_colname]\n",
    "fine_min_snr_uncs = planet.normed_uncertainty_df[fine_min_snr_colname]\n",
    "fine_temp = fine_min_snr_colname.split('_')[-1].split('x')\n",
    "fine_min_snr_aper_width, fine_min_snr_aper_height = np.int32(fine_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_message(f'Fine Aperture Photometry Resulted in {fine_min_snr:0.0f}ppm with '\n",
    "             f'{fine_min_snr_aper_width}x{fine_min_snr_aper_height} aperture size; '\n",
    "             f'with median uncertainties of {np.median(fine_min_snr_uncs)*1e6:0.0f} ppm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure system for PyMC3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jqJxdF0I7bTK"
   },
   "outputs": [],
   "source": [
    "idx_fwd = planet.idx_fwd\n",
    "idx_rev = planet.idx_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "colab_type": "code",
    "id": "6vGrEIEv7YnO",
    "outputId": "bfed0117-0b8a-423e-f2a1-13068d698e0e"
   },
   "outputs": [],
   "source": [
    "# Compute a limb-darkened light curve using starry\n",
    "times = planet.times\n",
    "u = []\n",
    "flux = planet.normed_photometry_df[fine_min_snr_colname]\n",
    "yerr = planet.normed_uncertainty_df[fine_min_snr_colname]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "colab_type": "code",
    "id": "6vGrEIEv7YnO",
    "outputId": "bfed0117-0b8a-423e-f2a1-13068d698e0e"
   },
   "source": [
    "plt.errorbar(times[idx_fwd], flux[idx_fwd], yerr[idx_fwd], fmt='o', color=\"C0\")\n",
    "plt.errorbar(times[idx_rev], flux[idx_rev], yerr[idx_rev], fmt='o', color=\"C3\")\n",
    "plt.axhline(1.0, ls='--', color='C1')\n",
    "plt.ylabel(\"relative flux\")\n",
    "plt.xlabel(\"time [days]\")\n",
    "plt.xlim(times.min(), times.max());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UDHaejnap_2d"
   },
   "source": [
    "But the real power comes from the fact that this is defined as a [Theano operation](http://deeplearning.net/software/theano/extending/extending_theano.html) so it can be combined with PyMC3 to do transit inference using Hamiltonian Monte Carlo.\n",
    "\n",
    "## The transit model in PyMC3\n",
    "\n",
    "In this section, we will construct a simple transit fit model using *PyMC3* and then we will fit a two planet model to simulated data.\n",
    "To start, let's randomly sample some periods and phases and then define the time sampling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "So0C6fKop_2g"
   },
   "source": [
    "Then, define the parameters.\n",
    "In this simple model, we'll just fit for the limb darkening parameters of the star, and the period, phase, impact parameter, and radius ratio of the planets (note: this is already 10 parameters and running MCMC to convergence using [emcee](https://emcee.readthedocs.io) would probably take at least an hour).\n",
    "For the limb darkening, we'll use a quadratic law as parameterized by [Kipping (2013)](https://arxiv.org/abs/1308.0009).\n",
    "This reparameterizations is implemented in *exoplanet* as custom *PyMC3* distribution :class:`exoplanet.distributions.QuadLimbDark`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "z-oUic6qrjXZ",
    "outputId": "85f6974f-cbc1-476a-d3ce-3372c7f02451"
   },
   "outputs": [],
   "source": [
    "print(f'This instance has {mp.cpu_count()} CPUs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planet_info = exoMAST_API('PlanetNameb')\n",
    "t0_planet = planet_info.transit_time  # 55528.3684  # exo.mast.stsci.edu\n",
    "period_planet = planet_info.orbital_period\n",
    "n_epochs = np.int(np.round(((np.median(times) - t0_planet) / period_planet)-0.5))\n",
    "t0_guess = t0_planet + (n_epochs+0.5) * period_planet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f5jMP0gg2Gxy"
   },
   "outputs": [],
   "source": [
    "b_planet = planet_info.impact_parameter # 0.66 # Hellier 2011\n",
    "u = [0]\n",
    "edepth = np.sqrt(500/1e6)\n",
    "\n",
    "orbit_planet = xo.orbits.KeplerianOrbit(period=period_planet, t0=t0_guess, b=b_planet)\n",
    "injected_light_curves = xo.LimbDarkLightCurve(u).get_light_curve(orbit=orbit_planet, r=edepth, t=times).eval().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "colab_type": "code",
    "id": "jcnrG-JX2l4Y",
    "outputId": "4def2a2b-1baa-4698-d8a1-3d55289ff259"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10,6)\n",
    "plt.errorbar(times, flux, yerr, fmt='o')#  * (injected_light_curves+1)\n",
    "plt.plot(times, injected_light_curves+1,'o')\n",
    "plt.ylabel(\"relative flux\")\n",
    "plt.xlabel(\"time [days]\")\n",
    "plt.xlim(times.min(), times.max());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppm = 1e6\n",
    "times_th = np.linspace(times.min(), times.max(), 1000)\n",
    "r_aic = np.sqrt(9/ppm)\n",
    "r_model1 = 45/ppm\n",
    "r_model2 = 100/ppm\n",
    "\n",
    "injected_light_curve_aic = xo.LimbDarkLightCurve(u).get_light_curve(orbit=orbit_planet, r=r_aic, t=times_th).eval().flatten()\n",
    "injected_light_curve_mdl1 = xo.LimbDarkLightCurve(u).get_light_curve(orbit=orbit_planet, r=r_model1, t=times_th).eval().flatten()\n",
    "injected_light_curve_mdl2 = xo.LimbDarkLightCurve(u).get_light_curve(orbit=orbit_planet, r=r_model2, t=times_th).eval().flatten()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10,6)\n",
    "\n",
    "plt.errorbar(times[idx_fwd], flux[idx_fwd], yerr[idx_fwd], fmt='o', label='Forward Scan')\n",
    "plt.errorbar(times[idx_rev], flux[idx_rev], yerr[idx_rev], fmt='o', label='Reverse Scan')\n",
    "plt.plot(times_th, injected_light_curve_aic+1, '--', label='Best AIC Model')\n",
    "plt.plot(times_th, injected_light_curve_mdl1+1, '--', label='f_sed > 0.1')\n",
    "plt.plot(times_th, injected_light_curve_mdl2+1, '--', label='f_sed = 0.1')\n",
    "plt.ylabel(\"Relative Flux [ppm]\")\n",
    "plt.xlabel(\"Time [days]\")\n",
    "plt.xlim(times.min(), times.max())\n",
    "plt.legend(loc=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run 400 MCMCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_snr_flux = planet.normed_photometry_df\n",
    "fine_snr_uncs = planet.normed_uncertainty_df\n",
    "\n",
    "n_columns = len(fine_snr_flux.columns)\n",
    "\n",
    "aper_sum_columns = planet.normed_photometry_df.drop(\n",
    "    ['xcenter', 'ycenter'], axis=1).columns\n",
    "\n",
    "xcenters = planet.photometry_df['xcenter']\n",
    "ycenters = planet.photometry_df['ycenter']\n",
    "xcenters_mod = xcenters - np.median(xcenters)\n",
    "ycenters_mod = ycenters - np.median(ycenters)\n",
    "times_mod = times - t0_guess#np.median(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_space = 2\n",
    "near_best_apertures_NxN_small = [f'aperture_sum_{aper_width_}x{aper_height_}' \n",
    "                       for aper_width_ in (np.arange(-n_space+1,n_space)+fine_min_snr_aper_width)\n",
    "                       for aper_height_ in (np.arange(-n_space+1,n_space)+fine_min_snr_aper_height)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "near_best_apertures_NxN_small,len(near_best_apertures_NxN_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN ALL 12 IN ONE FUNCTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from arctor.utils import run_all_12_options\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "tune = 3000\n",
    "draws = 3000\n",
    "target_accept = 0.9\n",
    "do_mcmc = False\n",
    "save_as_you_go = False\n",
    "\n",
    "base_name = f'{planet_name}_fine_grain_photometry_208ppm'\n",
    "base_name = f'{base_name}_near_best_{n_space}x{n_space}'\n",
    "near_best_apertures_NxN_small = [fine_min_snr_colname]  # aper_sum_columns,  #\n",
    "\n",
    "mcmc_fits_all_12 = run_all_12_options(times,\n",
    "                                      fine_snr_flux,\n",
    "                                      fine_snr_uncs,\n",
    "                                      near_best_apertures_NxN_small,\n",
    "                                      xcenters=planet.trace_xcenters - np.median(planet.trace_xcenters),\n",
    "                                      ycenters=planet.trace_ycenters - np.median(planet.trace_ycenters),\n",
    "                                      trace_angles=planet.trace_angles - np.median(planet.trace_angles),\n",
    "                                      trace_lengths=planet.trace_lengths - np.median(planet.trace_lengths),\n",
    "                                      t0=t0_guess,\n",
    "                                      u=u,\n",
    "                                      period=period_planet,\n",
    "                                      b=b_planet,\n",
    "                                      idx_fwd=idx_fwd,\n",
    "                                      idx_rev=idx_rev,\n",
    "                                      tune=tune,\n",
    "                                      draws=draws,\n",
    "                                      target_accept=target_accept,\n",
    "                                      do_mcmc=do_mcmc,\n",
    "                                      save_as_you_go=save_as_you_go,\n",
    "                                      injected_light_curve=1.0,\n",
    "                                      working_dir=working_dir,\n",
    "                                      base_name=base_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN ALL 12 MANUALLY"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start0 = time()\n",
    "# Linear Eclipse Depths with Negative Allowed\n",
    "start1 = time()\n",
    "print('Linear Eclipse depth fits - Allow Negative Eclipse Depths')\n",
    "fine_grain_mcmcs, filename = run_multiple_pymc3(\n",
    "    times, fine_snr_flux, fine_snr_uncs, near_best_apertures_NxN_small,\n",
    "    t0=t0_guess, u=u, period=period_planet, b=b_planet,\n",
    "    idx_fwd=idx_fwd, idx_rev=idx_rev,\n",
    "    tune=tune, draws=draws, target_accept=target_accept,\n",
    "    do_mcmc=do_mcmc, save_as_you_go=save_as_you_go,\n",
    "    injected_light_curve=1.0, base_name=base_name, working_dir=working_dir,\n",
    "    xcenters=None,\n",
    "    allow_negative_edepths=True,\n",
    "    use_rev_fwd_split=False,\n",
    "    use_log_edepth=False\n",
    ")\n",
    "\n",
    "fine_grain_mcmcs_no_xcenter_lin_edepth_no_split_w_negEcl = fine_grain_mcmcs\n",
    "filename_no_xcenter_lin_edepth_no_split_w_negEcl = filename\n",
    "print(f'[INFO] This MCMCs took {(time() - start1)/60:0.2f} minutes')\n",
    "\n",
    "del fine_grain_mcmcs, filename\n",
    "\n",
    "start1 = time()\n",
    "print('Linear Eclipse depth fits - Allow Negative Eclipse Depths with splitting fwd rev')\n",
    "fine_grain_mcmcs, filename = run_multiple_pymc3(\n",
    "    times, fine_snr_flux, fine_snr_uncs, near_best_apertures_NxN_small,\n",
    "    t0=t0_guess, u=u, period=period_planet, b=b_planet,\n",
    "    idx_fwd=idx_fwd, idx_rev=idx_rev,\n",
    "    tune=tune, draws=draws, target_accept=target_accept,\n",
    "    do_mcmc=do_mcmc, save_as_you_go=save_as_you_go,\n",
    "    injected_light_curve=1.0, base_name=base_name, working_dir=working_dir,\n",
    "    xcenters=None,  # SAME\n",
    "    allow_negative_edepths=True,  # SAME\n",
    "    use_rev_fwd_split=True,  # DIFFERENT\n",
    "    use_log_edepth=False  # SAME\n",
    ")\n",
    "fine_grain_mcmcs_with_no_xcenter_lin_edepth_w_split_w_negEcl = fine_grain_mcmcs\n",
    "filename_with_no_xcenter_lin_edepth_w_split_w_negEcl = filename\n",
    "\n",
    "print(f'[INFO] This MCMCs took {(time() - start1)/60:0.2f} minutes')\n",
    "\n",
    "del fine_grain_mcmcs, filename\n",
    "\n",
    "start1 = time()\n",
    "print('Linear Eclipse depth fits - Allow Negative Eclipse Depths with xcenter')\n",
    "fine_grain_mcmcs, filename = run_multiple_pymc3(\n",
    "    times, fine_snr_flux, fine_snr_uncs, near_best_apertures_NxN_small,\n",
    "    t0=t0_guess, u=u, period=period_planet, b=b_planet,\n",
    "    idx_fwd=idx_fwd, idx_rev=idx_rev,\n",
    "    tune=tune, draws=draws, target_accept=target_accept,\n",
    "    do_mcmc=do_mcmc, save_as_you_go=save_as_you_go,\n",
    "    injected_light_curve=1.0, base_name=base_name, working_dir=working_dir,\n",
    "    xcenters=xcenters_mod,  # DIFFERENT\n",
    "    allow_negative_edepths=True,  # SAME\n",
    "    use_rev_fwd_split=False,  # SAME\n",
    "    use_log_edepth=False,  # SAME\n",
    ")\n",
    "\n",
    "fine_grain_mcmcs_with_w_xcenter_lin_edepth_no_split_w_negEcl = fine_grain_mcmcs\n",
    "filename_with_w_xcenter_lin_edepth_no_split_w_negEcl = filename\n",
    "print(f'[INFO] This MCMCs took {(time() - start1)/60:0.2f} minutes')\n",
    "\n",
    "del fine_grain_mcmcs, filename\n",
    "\n",
    "start1 = time()\n",
    "print('Linear Eclipse depth fits - '\n",
    "      'Allow Negative Eclipse Depths with xcenter and splitting fwd rev')\n",
    "fine_grain_mcmcs, filename = run_multiple_pymc3(\n",
    "    times, fine_snr_flux, fine_snr_uncs, near_best_apertures_NxN_small,\n",
    "    t0=t0_guess, u=u, period=period_planet, b=b_planet,\n",
    "    idx_fwd=idx_fwd, idx_rev=idx_rev,\n",
    "    tune=tune, draws=draws, target_accept=target_accept,\n",
    "    do_mcmc=do_mcmc, save_as_you_go=save_as_you_go,\n",
    "    injected_light_curve=1.0, base_name=base_name, working_dir=working_dir,\n",
    "    xcenters=xcenters_mod,  # SAME\n",
    "    allow_negative_edepths=True,  # SAME\n",
    "    use_rev_fwd_split=True,  # DIFFERENT\n",
    "    use_log_edepth=False  # SAME\n",
    ")\n",
    "\n",
    "fine_grain_mcmcs_with_w_xcenter_lin_edepth_w_split_w_negEcl = fine_grain_mcmcs\n",
    "filename_with_w_xcenter_lin_edepth_w_split_w_negEcl = filename\n",
    "print(f'[INFO] This MCMCs took {(time() - start1)/60:0.2f} minutes')\n",
    "\n",
    "del fine_grain_mcmcs, filename\n",
    "\n",
    "start1 = time()\n",
    "# Linear Eclipse Depths without Negative Allowed\n",
    "print('Linear Eclipse depth fits - Default everything')t\n",
    "fine_grain_mcmcs, filename = run_multiple_pymc3(\n",
    "    times, fine_snr_flux, fine_snr_uncs, near_best_apertures_NxN_small,\n",
    "    t0=t0_guess, u=u, period=period_planet, b=b_planet, idx_fwd=idx_fwd, idx_rev=idx_rev,\n",
    "    tune=tune, draws=draws, target_accept=target_accept,\n",
    "    injected_light_curve=1.0, base_name=base_name, working_dir=working_dir,\n",
    "    do_mcmc=do_mcmc, save_as_you_go=save_as_you_go,\n",
    "    xcenters=None,  # DIFFERENT\n",
    "    allow_negative_edepths=False,  # DIFFERENT\n",
    "    use_rev_fwd_split=False,  # DIFFERENT\n",
    "    use_log_edepth=False  # SAME\n",
    ")\n",
    "\n",
    "fine_grain_mcmcs_with_no_xcenter_lin_edepth_no_split = fine_grain_mcmcs\n",
    "filename_with_no_xcenter_lin_edepth_no_split = filename\n",
    "print(f'[INFO] This MCMCs took {(time() - start1)/60:0.2f} minutes')\n",
    "\n",
    "del fine_grain_mcmcs, filename\n",
    "\n",
    "start1 = time()\n",
    "print('Linear Eclipse depth fits - Everything with splitting fwd rev')\n",
    "fine_grain_mcmcs, filename = run_multiple_pymc3(\n",
    "    times, fine_snr_flux, fine_snr_uncs, near_best_apertures_NxN_small,\n",
    "    t0=t0_guess, u=u, period=period_planet, b=b_planet, idx_fwd=idx_fwd, idx_rev=idx_rev,\n",
    "    tune=tune, draws=draws, target_accept=target_accept,\n",
    "    injected_light_curve=1.0, base_name=base_name, working_dir=working_dir,\n",
    "    do_mcmc=do_mcmc, save_as_you_go=save_as_you_go,\n",
    "    xcenters=None,  # SAME\n",
    "    allow_negative_edepths=False,  # SAME\n",
    "    use_rev_fwd_split=True,  # DIFFERENT\n",
    "    use_log_edepth=False,  # SAME\n",
    ")\n",
    "\n",
    "fine_grain_mcmcs_with_no_xcenter_lin_edepth_w_split = fine_grain_mcmcs\n",
    "filename_with_no_xcenter_lin_edepth_w_split = filename\n",
    "\n",
    "print(f'[INFO] This MCMCs took {(time() - start1)/60:0.2f} minutes')\n",
    "\n",
    "del fine_grain_mcmcs, filename\n",
    "\n",
    "start1 = time()\n",
    "print('Linear Eclipse depth fits - Everything with xcenter')\n",
    "fine_grain_mcmcs, filename = run_multiple_pymc3(\n",
    "    times, fine_snr_flux, fine_snr_uncs, near_best_apertures_NxN_small,\n",
    "    t0=t0_guess, u=u, period=period_planet, b=b_planet,\n",
    "    idx_fwd=idx_fwd, idx_rev=idx_rev,\n",
    "    tune=tune, draws=draws, target_accept=target_accept,\n",
    "    do_mcmc=do_mcmc, save_as_you_go=save_as_you_go,\n",
    "    injected_light_curve=1.0, base_name=base_name, working_dir=working_dir,\n",
    "    xcenters=xcenters_mod,  # DIFFERENT\n",
    "    allow_negative_edepths=False,  # SAME\n",
    "    use_rev_fwd_split=False,  # DIFFERENT\n",
    "    use_log_edepth=False  # SAME\n",
    ")\n",
    "\n",
    "fine_grain_mcmcs_with_w_xcenter_lin_edepth_no_split = fine_grain_mcmcs\n",
    "filename_with_w_xcenter_lin_edepth_no_split = filename\n",
    "\n",
    "print(f'[INFO] This MCMCs took {(time() - start1)/60:0.2f} minutes')\n",
    "\n",
    "del fine_grain_mcmcs, filename\n",
    "\n",
    "start1 = time()\n",
    "print('Linear Eclipse depth fits - '\n",
    "      'Everything with xcenter and splitting fwd rev')\n",
    "fine_grain_mcmcs, filename = run_multiple_pymc3(\n",
    "    times, fine_snr_flux, fine_snr_uncs, near_best_apertures_NxN_small,\n",
    "    t0=t0_guess, u=u, period=period_planet, b=b_planet,\n",
    "    idx_fwd=idx_fwd, idx_rev=idx_rev,\n",
    "    tune=tune, draws=draws, target_accept=target_accept,\n",
    "    do_mcmc=do_mcmc, save_as_you_go=save_as_you_go,\n",
    "    injected_light_curve=1.0, base_name=base_name, working_dir=working_dir,\n",
    "    xcenters=xcenters_mod,  # SAME\n",
    "    allow_negative_edepths=False,  # SAME\n",
    "    use_rev_fwd_split=True,  # DIFFERENT\n",
    "    use_log_edepth=False)  # SAME\n",
    "\n",
    "fine_grain_mcmcs_with_w_xcenter_lin_edepth_w_split = fine_grain_mcmcs\n",
    "filename_with_w_xcenter_lin_edepth_w_split = filename\n",
    "\n",
    "print(f'[INFO] This MCMCs took {(time() - start1)/60:0.2f} minutes')\n",
    "\n",
    "del fine_grain_mcmcs, filename\n",
    "\n",
    "# Logarithmic Eclipse Depths\n",
    "start1 = time()\n",
    "print('Log Eclipse depth fits - Default everything')\n",
    "fine_grain_mcmcs, filename = run_multiple_pymc3(\n",
    "    times, fine_snr_flux, fine_snr_uncs, near_best_apertures_NxN_small,\n",
    "    t0=t0_guess, u=u, period=period_planet, b=b_planet,\n",
    "    idx_fwd=idx_fwd, idx_rev=idx_rev,\n",
    "    tune=tune, draws=draws, target_accept=target_accept,\n",
    "    do_mcmc=do_mcmc, save_as_you_go=save_as_you_go,\n",
    "    injected_light_curve=1.0, base_name=base_name, working_dir=working_dir,\n",
    "    xcenters=None,  # DIFFERENT\n",
    "    allow_negative_edepths=False,  # SAME\n",
    "    use_rev_fwd_split=False,  # DIFFERENT\n",
    "    use_log_edepth=True  # DIFFERENT\n",
    ")\n",
    "\n",
    "fine_grain_mcmcs_with_no_xcenter_log_edepth_no_split = fine_grain_mcmcs\n",
    "filename_with_no_xcenter_log_edepth_no_split = filename\n",
    "\n",
    "print(f'[INFO] This MCMCs took {(time() - start1)/60:0.2f} minutes')\n",
    "\n",
    "del fine_grain_mcmcs, filename\n",
    "\n",
    "start1 = time()\n",
    "print('Log Eclipse depth fits - Everything with splitting fwd rev')\n",
    "fine_grain_mcmcs, filename = run_multiple_pymc3(\n",
    "    times, fine_snr_flux, fine_snr_uncs, near_best_apertures_NxN_small,\n",
    "    t0=t0_guess, u=u, period=period_planet, b=b_planet,\n",
    "    idx_fwd=idx_fwd, idx_rev=idx_rev,\n",
    "    tune=tune, draws=draws, target_accept=target_accept,\n",
    "    do_mcmc=do_mcmc, save_as_you_go=save_as_you_go,\n",
    "    injected_light_curve=1.0, base_name=base_name, working_dir=working_dir,\n",
    "    xcenters=None,  # SAME\n",
    "    allow_negative_edepths=False,  # SAME\n",
    "    use_rev_fwd_split=True,  # DIFFERENT\n",
    "    use_log_edepth=True  # SAME\n",
    ")\n",
    "\n",
    "fine_grain_mcmcs_with_no_xcenter_log_edepth_w_split = fine_grain_mcmcs\n",
    "filename_with_no_xcenter_log_edepth_w_split = filename\n",
    "\n",
    "print(f'[INFO] This MCMCs took {(time() - start1)/60:0.2f} minutes')\n",
    "\n",
    "start1 = time()\n",
    "print('Log Eclipse depth fits - Everything with xcenter')\n",
    "fine_grain_mcmcs, filename = run_multiple_pymc3(\n",
    "    times, fine_snr_flux, fine_snr_uncs, near_best_apertures_NxN_small,\n",
    "    t0=t0_guess, u=u, period=period_planet, b=b_planet,\n",
    "    idx_fwd=idx_fwd, idx_rev=idx_rev,\n",
    "    tune=tune, draws=draws, target_accept=target_accept,\n",
    "    do_mcmc=do_mcmc, save_as_you_go=save_as_you_go,\n",
    "    injected_light_curve=1.0, base_name=base_name, working_dir=working_dir,\n",
    "    xcenters=xcenters_mod,  # DIFFERENT\n",
    "    allow_negative_edepths=False,  # SAME\n",
    "    use_rev_fwd_split=False,  # DIFFERENT\n",
    "    use_log_edepth=True  # SAME\n",
    ")\n",
    "\n",
    "fine_grain_mcmcs_with_w_xcenter_log_edepth_no_split = fine_grain_mcmcs\n",
    "filename_with_w_xcenter_log_edepth_no_split = filename\n",
    "\n",
    "print(f'[INFO] This MCMCs took {(time() - start1)/60:0.2f} minutes')\n",
    "\n",
    "del fine_grain_mcmcs, filename\n",
    "\n",
    "start1 = time()\n",
    "print('Log Eclipse depth fits - Everything with xcenter and splitting fwd rev')\n",
    "fine_grain_mcmcs, filename = run_multiple_pymc3(\n",
    "    times, fine_snr_flux, fine_snr_uncs, near_best_apertures_NxN_small,\n",
    "    t0=t0_guess, u=u, period=period_planet, b=b_planet,\n",
    "    idx_fwd=idx_fwd, idx_rev=idx_rev,\n",
    "    tune=tune, draws=draws, target_accept=target_accept,\n",
    "    do_mcmc=do_mcmc, save_as_you_go=save_as_you_go,\n",
    "    injected_light_curve=1.0, base_name=base_name, working_dir=working_dir,\n",
    "    xcenters=xcenters_mod,  # SAME\n",
    "    allow_negative_edepths=False,  # SAME\n",
    "    use_rev_fwd_split=True,  # DIFFERENT\n",
    "    use_log_edepth=True  # SAME\n",
    ")\n",
    "\n",
    "fine_grain_mcmcs_with_w_xcenter_log_edepth_w_split = fine_grain_mcmcs\n",
    "filename_with_w_xcenter_log_edepth_w_split = filename\n",
    "\n",
    "print(f'[INFO] This MCMCs took {(time() - start1)/60:0.2f} minutes')\n",
    "\n",
    "print(f'[INFO] All 12 MCMCs took {(time() - start0)/60:0.2f} minutes')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# allow negative\n",
    "[slope, edepth, mean]\n",
    "[slope, edepth, mean_rev, mean_fwd]\n",
    "[slope_xcenter, slope, edepth, mean]\n",
    "[slope_xcenter, slope, edepth, mean_rev, mean_fwd]\n",
    "\n",
    "# all positive\n",
    "[slope, edepth, mean]\n",
    "[slope, edepth, mean_rev, mean_fwd]\n",
    "[slope_xcenter, slope, edepth, mean]\n",
    "[slope_xcenter, slope, edepth, mean_rev, mean_fwd]\n",
    "\n",
    "# log edepth\n",
    "[slope, log_edepth, mean]\n",
    "[slope, log_edepth, mean_rev, mean_fwd]\n",
    "[slope_xcenter, slope, log_edepth, mean]\n",
    "[slope_xcenter, slope, log_edepth, mean_rev, mean_fwd]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine all 12 manually"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mcmc_fits = [fine_grain_mcmcs_with_no_xcenter_lin_edepth_no_split_w_negEcl,\n",
    "             fine_grain_mcmcs_with_no_xcenter_lin_edepth_w_split_w_negEcl,\n",
    "             fine_grain_mcmcs_with_w_xcenter_lin_edepth_no_split_w_negEcl,\n",
    "             fine_grain_mcmcs_with_w_xcenter_lin_edepth_w_split_w_negEcl,\n",
    "             fine_grain_mcmcs_with_no_xcenter_lin_edepth_no_split,\n",
    "             fine_grain_mcmcs_with_no_xcenter_lin_edepth_w_split,\n",
    "             fine_grain_mcmcs_with_w_xcenter_lin_edepth_no_split,\n",
    "             fine_grain_mcmcs_with_w_xcenter_lin_edepth_w_split,\n",
    "             fine_grain_mcmcs_with_no_xcenter_log_edepth_no_split,\n",
    "             fine_grain_mcmcs_with_no_xcenter_log_edepth_w_split,\n",
    "             fine_grain_mcmcs_with_w_xcenter_log_edepth_no_split,\n",
    "             fine_grain_mcmcs_with_w_xcenter_log_edepth_w_split\n",
    "            ]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.rcParams['figure.figsize'] = 8,6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing new \"all correlations and all flavors\" MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HERE"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_space = 10\n",
    "near_best_apertures_NxN_small = [f'aperture_sum_{aper_width_}x{aper_height_}' \n",
    "                                 for aper_width_ in (np.arange(-n_space//2+1, n_space//2+1)+fine_min_snr_aper_width)\n",
    "                                 for aper_height_ in (np.arange(-n_space//2+1, n_space//2+1)+fine_min_snr_aper_height)]\n",
    "len(near_best_apertures_NxN_small)#, near_best_apertures_NxN_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for colname in planet.normed_photometry_df.columns:\n",
    "    if 'center' in colname:\n",
    "        print(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(HOME, 'path', 'to', 'notebooks', 'savefiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin BIG GP Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for aper_column in planet.normed_photometry_df.columns:  # near_best_apertures_NxN_small:  # [fine_min_snr_colname]:\n",
    "    if 'center' in aper_column:\n",
    "        continue\n",
    "\n",
    "    save_name = f'{save_dir}/results_decor_span_MAPs_only_SDNR_w_GPs_{aper_column}.joblib.save'\n",
    "    if os.path.exists(save_name):\n",
    "        print(os.path.exists(save_name), save_name.split('/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arctor.utils import run_pymc3_w_gp\n",
    "\n",
    "tune = 3000\n",
    "draws = 3000\n",
    "target_accept = 0.9\n",
    "do_mcmc = False\n",
    "idx_fwd_ = None\n",
    "idx_rev_ = None\n",
    "use_log_edepth = False\n",
    "allow_negative_edepths = False\n",
    "use_pink_gp = True\n",
    "normalize=True\n",
    "verbose=True\n",
    "\n",
    "xcenters_mod = planet.trace_xcenters - np.median(planet.trace_xcenters)\n",
    "ycenters_mod = planet.trace_ycenters - np.median(planet.trace_ycenters)\n",
    "trace_angles_mod = planet.trace_angles - np.median(planet.trace_angles)\n",
    "trace_lengths_mod = planet.trace_lengths - np.median(planet.trace_lengths)\n",
    "phots = planet.normed_photometry_df[fine_min_snr_colname].values\n",
    "phots = phots - np.median(phots)\n",
    "\n",
    "# n_space = 10\n",
    "# near_best_apertures_NxN_small = [f'aperture_sum_{aper_width_}x{aper_height_}' \n",
    "#                                  for aper_width_ in (np.arange(-n_space//2+1, n_space//2+1)+fine_min_snr_aper_width)\n",
    "#                                  for aper_height_ in (np.arange(-n_space//2+1, n_space//2+1)+fine_min_snr_aper_height)]\n",
    "# # len(near_best_apertures_NxN_small)# near_best_apertures_NxN_small\n",
    "# save_dir = os.path.join(HOME, 'path', 'to', 'savefiles')\n",
    "\n",
    "decor_span_MAPs_only_list_all400 = []\n",
    "startn1 = time()\n",
    "for aper_column in planet.normed_photometry_df.columns:  # near_best_apertures_NxN_small:  # [fine_min_snr_colname]:\n",
    "    if 'center' in aper_column:\n",
    "        continue\n",
    "\n",
    "    save_name = f'{save_dir}/results_decor_span_MAPs_only_SDNR_w_GPs_{aper_column}.joblib.save'\n",
    "    if os.path.exists(save_name):\n",
    "        if verbose:\n",
    "            print(f'[INFO] File exists: {save_name}. Skipping')\n",
    "        continue\n",
    "\n",
    "    phots = planet.normed_photometry_df[aper_column].values\n",
    "    uncs = planet.normed_uncertainty_df[aper_column].values\n",
    "    save_state = {}\n",
    "    save_state[aper_column] = []\n",
    "    start0 = time()\n",
    "    # Turned off to improve usage with GPs\n",
    "    for xcenters_ in [None, xcenters_mod]:\n",
    "        start2 = time()\n",
    "        for ycenters_ in [None, ycenters_mod]:\n",
    "            start3 = time()\n",
    "            for trace_angles_ in [None, trace_angles_mod]:\n",
    "                start4 = time()\n",
    "                for trace_lengths_ in [None, trace_lengths_mod]:\n",
    "                    start5 = time()\n",
    "                    # Only set to True because the False case was created months ago\n",
    "                    for use_pink_gp in [True]:  # [True, False]:\n",
    "                        start6 = time()\n",
    "                        fine_grain_mcmcs, map_soln = run_pymc3_w_gp(\n",
    "                            times, phots, uncs,\n",
    "                            t0=t0_guess, u=u, period=period_planet, b=b_planet,\n",
    "                            tune=tune, draws=draws, target_accept=target_accept,\n",
    "                            xcenters=xcenters_,\n",
    "                            ycenters=ycenters_,\n",
    "                            trace_angles=trace_angles_,\n",
    "                            trace_lengths=trace_lengths_,\n",
    "                            do_mcmc=False,\n",
    "                            use_pink_gp=use_pink_gp,\n",
    "                            normalize=normalize,\n",
    "                            verbose=verbose)\n",
    "\n",
    "                        info_message(f'Full decorrelation took {(time() - start6)/60:0.2f} minutes')\n",
    "                        res_std_ppm, phots_std_ppm, res_diff_ppm = compute_delta_sdnr(map_soln, phots, idx_fwd, idx_rev)\n",
    "\n",
    "                        save_state_ = [idx_fwd_ is not None,\n",
    "                                       idx_rev_ is not None,\n",
    "                                       xcenters_ is not None,\n",
    "                                       ycenters_ is not None,\n",
    "                                       trace_angles_ is not None,\n",
    "                                       trace_lengths_ is not None,\n",
    "                                       use_pink_gp]\n",
    "\n",
    "                        save_state_.extend([fine_grain_mcmcs, map_soln])\n",
    "                        save_state_.extend([res_std_ppm, phots_std_ppm, res_diff_ppm])\n",
    "\n",
    "                        save_state[aper_column].append(save_state_)\n",
    "                        # decor_span_MAPs_only_list_all400.append(save_state)\n",
    "                    info_message(f'Use Pink GP Option took {(time() - start5)/60:0.2f} minutes')\n",
    "                info_message(f'Trace Length Option took {(time() - start4)/60:0.2f} minutes')\n",
    "            info_message(f'Trace Angle Option took {(time() - start3)/60:0.2f} minutes')\n",
    "        info_message(f'Ycenter Option took {(time() - start2)/60:0.2f} minutes')\n",
    "    # info_message(f'Xcenter Option took {(time() - start1)/60:0.2f} minutes')\n",
    "    info_message(f'Run through for {aper_column} took {(time() - start0)/60:0.2f} minutes')\n",
    "    \n",
    "    print(f'[INFO] Saving {aper_column} to {save_name}')\n",
    "    joblib.dump(save_state, save_name)\n",
    "    del save_state\n",
    "\n",
    "info_message(f'Entire loop-d-loop took {(time() - startn1)/60:0.2f} minutes')\n",
    "\n",
    "# joblib.dump(decor_span_MAPs_only_list_all400, f'{save_dir}/results_decor_span_MAPs_only_SDNR_all400.joblib.save')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END GP Test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "joblib.dump(decor_span_MAPs_only_list, 'results_decor_span_MAPs_only_SDNR_all400.joblib.save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_space = 5\n",
    "near_best_apertures_NxN_small = [f'aperture_sum_{aper_width_}x{aper_height_}' \n",
    "                                 for aper_width_ in (np.arange(-n_space//2+1, n_space//2+1)+fine_min_snr_aper_width)\n",
    "                                 for aper_height_ in (np.arange(-n_space//2+1, n_space//2+1)+fine_min_snr_aper_height)]\n",
    "len(near_best_apertures_NxN_small), near_best_apertures_NxN_small"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "decor_aper_columns_list = []\n",
    "for aper_column in near_best_apertures_NxN_small:  # planet.normed_photometry_df.columns:  # [fine_min_snr_colname]:\n",
    "    for idx_fwd_, idx_rev_ in zip([None, idx_fwd], [None, idx_rev]):\n",
    "        for xcenters_ in [None, xcenters_mod]:\n",
    "            for ycenters_ in [None, ycenters_mod]:\n",
    "                for trace_angles_ in [None, trace_angles_mod]:\n",
    "                    for trace_lengths_ in [None, trace_lengths_mod]:\n",
    "                        decor_aper_columns_list.append(aper_column)\n",
    "\n",
    "joblib.dump(decor_aper_columns_list, 'decor_span_MAPs_only_aper_columns_list.joblib.save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(decor_aper_columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(HOME, 'path', 'to', 'savefiles')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from arctor.utils import run_pymc3_both, compute_delta_sdnr\n",
    "\n",
    "tune = 3000\n",
    "draws = 3000\n",
    "target_accept = 0.9\n",
    "do_mcmc = True\n",
    "idx_fwd_ = None\n",
    "idx_rev_ = None\n",
    "use_log_edepth = False\n",
    "allow_negative_edepths = False\n",
    "\n",
    "xcenters_mod = planet.trace_xcenters - np.median(planet.trace_xcenters)\n",
    "ycenters_mod = planet.trace_ycenters - np.median(planet.trace_ycenters)\n",
    "trace_angles_mod = planet.trace_angles - np.median(planet.trace_angles)\n",
    "trace_lengths_mod = planet.trace_lengths - np.median(planet.trace_lengths)\n",
    "phots = planet.normed_photometry_df[fine_min_snr_colname].values\n",
    "\n",
    "# near_best_apertures_NxN_small = [fine_min_snr_colname]\n",
    "n_space = 5\n",
    "near_best_apertures_NxN_small = [f'aperture_sum_{aper_width_}x{aper_height_}' \n",
    "                                 for aper_width_ in (np.arange(-n_space//2+1, n_space//2+1)+fine_min_snr_aper_width)\n",
    "                                 for aper_height_ in (np.arange(-n_space//2+1, n_space//2+1)+fine_min_snr_aper_height)]\n",
    "\n",
    "save_dir = os.path.join(HOME, 'path', 'to', 'savefiles')\n",
    "# decor_span_MCMCs_list = []\n",
    "startn1 = time()\n",
    "for aper_column in near_best_apertures_NxN_small:  # [fine_min_snr_colname]:  # planet.normed_photometry_df.columns:  # near_best_apertures_NxN_small:  # \n",
    "    if 'center' in aper_column:\n",
    "        continue\n",
    "\n",
    "    save_name = f'{save_dir}/results_decor_span_MCMCs_25_bestest_SDNR_{aper_column}.joblib.save'\n",
    "    if os.path.exists(save_dir):\n",
    "        continue\n",
    "\n",
    "    phots = planet.normed_photometry_df[aper_column].values\n",
    "    uncs = planet.normed_uncertainty_df[aper_column].values\n",
    "    save_state = {}\n",
    "    save_state[aper_column] = []\n",
    "    start0 = time()\n",
    "    for idx_fwd_, idx_rev_ in zip([None, idx_fwd], [None, idx_rev]):\n",
    "        start1 = time()\n",
    "        for xcenters_ in [None, xcenters_mod]:\n",
    "            start2 = time()\n",
    "            for ycenters_ in [None, ycenters_mod]:\n",
    "                start3 = time()\n",
    "                for trace_angles_ in [None, trace_angles_mod]:\n",
    "                    start4 = time()\n",
    "                    for trace_lengths_ in [None, trace_lengths_mod]:\n",
    "                        start5 = time()\n",
    "                        fine_grain_mcmcs, map_soln = run_pymc3_both(\n",
    "                            times, phots, uncs,\n",
    "                            t0=t0_guess, u=u, period=period_planet, b=b_planet,\n",
    "                            tune=tune, draws=draws, target_accept=target_accept,\n",
    "                            xcenters=xcenters_,\n",
    "                            ycenters=ycenters_,\n",
    "                            trace_angles=trace_angles_,\n",
    "                            trace_lengths=trace_lengths_,\n",
    "                            do_mcmc=do_mcmc,\n",
    "                            idx_fwd=idx_fwd_,\n",
    "                            idx_rev=idx_rev_,\n",
    "                            use_log_edepth=use_log_edepth,\n",
    "                            allow_negative_edepths=allow_negative_edepths)\n",
    "                        \n",
    "                        info_message(f'Full decorrelation took {(time() - start5)/60:0.2f} minutes')\n",
    "                        res_std_ppm, phots_std_ppm, res_diff_ppm = compute_delta_sdnr(map_soln, phots, idx_fwd, idx_rev)\n",
    "                        \n",
    "                        save_state_ = [idx_fwd_ is not None,\n",
    "                                       idx_rev is not None,\n",
    "                                       xcenters_ is not None,\n",
    "                                       ycenters_ is not None,\n",
    "                                       trace_angles_ is not None,\n",
    "                                       trace_lengths_ is not None]\n",
    "                        \n",
    "                        save_state_.extend([aper_column, fine_grain_mcmcs, map_soln])\n",
    "                        save_state_.extend([res_std_ppm, phots_std_ppm, res_diff_ppm])\n",
    "                        \n",
    "                        save_state[aper_column].append(save_state_)\n",
    "                        # decor_span_MCMCs_list.append(save_state)\n",
    "                    info_message(f'Trace Length Option took {(time() - start4)/60:0.2f} minutes')\n",
    "                info_message(f'Trace Angle Option took {(time() - start3)/60:0.2f} minutes')\n",
    "            info_message(f'Ycenter Option took {(time() - start2)/60:0.2f} minutes')\n",
    "        info_message(f'xcenter Option took {(time() - start1)/60:0.2f} minutes')\n",
    "    info_message(f'Run through for {aper_column} took {(time() - start0)/60:0.2f} minutes')\n",
    "    \n",
    "    print(f'[INFO] Saving {aper_column} to {save_name}')\n",
    "    \n",
    "    joblib.dump(save_state, save_name)\n",
    "    del save_state\n",
    "\n",
    "info_message(f'Entire loop-d-loop took {(time() - startn1)/60:0.2f} minutes')\n",
    "\n",
    "# joblib.dump(decor_span_MCMCs_list, 'results_decor_span_MCMCs_25_bestest_SDNR.joblib.save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_fit_ = fine_grain_mcmcs_w_xcenter_w_ycenter_w_trace_angle_w_trace_length_lin_edepth_no_split_w_negEcl\n",
    "map_soln_ = map_soln_w_xcenter_w_ycenter_w_trace_angle_w_trace_length_lin_edepth_no_split_w_negEcl\n",
    "# map_soln_ = map_soln_no_decor_lin_edepth_no_split_w_negEcl\n",
    "# mcmc_fits_ = fine_grain_mcmcs_no_decor_lin_edepth_no_split_w_negEcl\n",
    "ppm = 1e6\n",
    "\n",
    "phots = planet.normed_photometry_df[fine_min_snr_colname].values\n",
    "phots_std = phots.std()*ppm\n",
    "varnames = [key for key in map_soln_.keys() if '__' not in key and 'light' not in key and 'line' not in key and 'le_edepth_0' not in key]\n",
    "label_mcmc_fit_ = str(varnames)\n",
    "\n",
    "if 'mean_fwd' not in map_soln_.keys():\n",
    "    map_model = map_soln_['light_curves'].flatten() + map_soln_['mean'] + map_soln_['slope']*(times - np.median(times))\n",
    "    if 'slope_xcenter' in map_soln_.keys():\n",
    "        map_model = map_model + map_soln_['slope_xcenter']*(xcenters.values - np.median(xcenters))\n",
    "else:\n",
    "    map_model = np.zeros_like(times)\n",
    "    map_model[idx_fwd] = map_soln_['light_curves_fwd'].flatten() + map_soln_['mean_fwd'] + map_soln_['slope']*(times[idx_fwd] - np.median(times))\n",
    "    map_model[idx_rev] = map_soln_['light_curves_rev'].flatten() + map_soln_['mean_rev'] + map_soln_['slope']*(times[idx_rev] - np.median(times))\n",
    "\n",
    "    if 'slope_xcenter' in map_soln_.keys():\n",
    "        map_model = map_model + map_soln_['slope_xcenter']*(xcenters.values - np.median(xcenters))\n",
    "\n",
    "print(f'{label_mcmc_fit_}: {phots_std - (np.std(map_model - phots))*ppm:0.2f} ppm difference')\n",
    "print(pm.summary(mcmc_fit_, varnames=varnames)[['mean', 'sd', 'hpd_2.5', 'hpd_97.5']])\n",
    "setup_and_plot_GTC({'trace':mcmc_fit_, 'map_soln':map_soln_},\n",
    "                   smoothingKernel=0.1, square_edepth=False,\n",
    "                   varnames=varnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcmc_fit_ = fine_grain_mcmcs_w_xcenter_w_ycenter_w_trace_angle_w_trace_length_lin_edepth_no_split_w_negEcl\n",
    "# map_soln_ = map_soln_w_xcenter_w_ycenter_w_trace_angle_w_trace_length_lin_edepth_no_split_w_negEcl\n",
    "map_soln_ = map_soln_no_decor_lin_edepth_no_split_w_negEcl\n",
    "mcmc_fits_ = fine_grain_mcmcs_no_decor_lin_edepth_no_split_w_negEcl\n",
    "ppm = 1e6\n",
    "\n",
    "phots = planet.normed_photometry_df[fine_min_snr_colname].values\n",
    "phots_std = phots.std()*ppm\n",
    "varnames = [key for key in map_soln_.keys() if '__' not in key and 'light' not in key and 'line' not in key and 'le_edepth_0' not in key]\n",
    "label_mcmc_fit_ = str(varnames)\n",
    "\n",
    "if 'mean_fwd' not in map_soln_.keys():\n",
    "    map_model = map_soln_['light_curves'].flatten() + map_soln_['mean'] + map_soln_['slope']*(times - np.median(times))\n",
    "    if 'slope_xcenter' in map_soln_.keys():\n",
    "        map_model = map_model + map_soln_['slope_xcenter']*(xcenters.values - np.median(xcenters))\n",
    "else:\n",
    "    map_model = np.zeros_like(times)\n",
    "    map_model[idx_fwd] = map_soln_['light_curves_fwd'].flatten() + map_soln_['mean_fwd'] + map_soln_['slope']*(times[idx_fwd] - np.median(times))\n",
    "    map_model[idx_rev] = map_soln_['light_curves_rev'].flatten() + map_soln_['mean_rev'] + map_soln_['slope']*(times[idx_rev] - np.median(times))\n",
    "    map_model[idx_rev] = map_model[idx_rev] + \n",
    "    # if 'slope_xcenter' in map_soln_.keys():\n",
    "    #     map_model = map_model + map_soln_['slope_xcenter']*(xcenters.values - np.median(xcenters))\n",
    "\n",
    "print(f'{label_mcmc_fit_}: {phots_std - (np.std(map_model - phots))*ppm:0.2f} ppm difference')\n",
    "print(pm.summary(mcmc_fit_, varnames=varnames)[['mean', 'sd', 'hpd_2.5', 'hpd_97.5']])\n",
    "setup_and_plot_GTC({'trace':mcmc_fit_, 'map_soln':map_soln_},\n",
    "                   smoothingKernel=0.1, square_edepth=False,\n",
    "                   varnames=varnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "varnames_ = varnames\n",
    "pm.traceplot(mcmc_fit_, var_names=varnames_);\n",
    "info_message(f'Time to plot {len(varnames_)} vars: {time() - start:0.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run  through All 12 (original) MCMC Flavors to Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_fits = [{fine_min_snr_colname:{'trace':fine_grain_mcmcs_no_decor_lin_edepth_no_split_w_negEcl,\n",
    "             'map_soln':map_soln_no_decor_lin_edepth_no_split_w_negEcl}},\n",
    "            {fine_min_snr_colname:{'trace':fine_grain_mcmcs_w_xcenter_w_ycenter_w_trace_angle_w_trace_length_lin_edepth_no_split_w_negEcl,\n",
    "             'map_soln':map_soln_w_xcenter_w_ycenter_w_trace_angle_w_trace_length_lin_edepth_no_split_w_negEcl}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mcmc_fit = []\n",
    "for mcmc_fit_ in mcmc_fits:\n",
    "    label_mcmc_fit.append(str([key for key in mcmc_fit_[fine_min_snr_colname]['map_soln'].keys() if '__' not in key and 'light' not in key]))\n",
    "\n",
    "for k in range(len(mcmc_fits)):\n",
    "    label_mcmc_fit[k] = label_mcmc_fit[k][:-1] + \", 'allow_neg_slopes']\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppm = 1e6\n",
    "phots = planet.normed_photometry_df[fine_min_snr_colname].values\n",
    "phots_std = phots.std()\n",
    "for k, mcmc_fit_ in enumerate(mcmc_fits):\n",
    "    map_soln = mcmc_fit_[fine_min_snr_colname]['map_soln']\n",
    "    if 'mean_fwd' not in map_soln.keys():\n",
    "        map_model = map_soln['light_curves'].flatten() + map_soln['line_model']\n",
    "    else:\n",
    "        map_model = np.zeros_like(times)\n",
    "        map_model[idx_fwd] = map_soln['light_curves_fwd'].flatten() + map_soln['line_model_fwd']\n",
    "        map_model[idx_rev] = map_soln['light_curves_rev'].flatten() + map_soln['line_model_rev']\n",
    "\n",
    "    print(f'{label_mcmc_fit[k]:<80}')\n",
    "    print(f'{phots_std*ppm:0.2f}, {np.std(map_model - phots)*ppm:0.2f}, {phots_std*ppm - (np.std(map_model - phots))*ppm:0.2f} ppm difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, mcmc_fit_ in enumerate(mcmc_fits):\n",
    "    print(pm.summary(trace, varnames=varnames)[['mean', 'sd', 'hpd_2.5', 'hpd_97.5']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, mcmc_fit_ in enumerate(mcmc_fits):\n",
    "    setup_and_plot_GTC(mcmc_fit_[fine_min_snr_colname])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MCMC from Save Save 13x45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(HOME, 'path', 'to', 'notebooks')\n",
    "aper_column = 'aperture_sum_13x45'\n",
    "save_name = f'{save_dir}/results_decor_span_MCMCs_25_bestest_SDNR_{aper_column}_samples_df.csv'\n",
    "samples_df = pd.read_csv(save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defunct Analysis Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[key for key in fine_grain_mcmcs_with_w_xcenter_lin_edepth_w_split['aperture_sum_20x50']['map_soln'].keys()\n",
    "                if '__' not in key and 'light' not in key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(trace, varnames=varnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygtc\n",
    "plt.rcParams['figure.figsize'] = 10,10\n",
    "\n",
    "trace = fine_grain_mcmcs_w_xcenterfit[fine_min_snr_colname]['trace']\n",
    "\n",
    "samples = pm.trace_to_dataframe(trace, varnames=varnames)\n",
    "samples['edepth'] = 10**samples['log_edepth']\n",
    "\n",
    "pygtc.plotGTC(samples, nContourLevels=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erf\n",
    "sigmas = erf(np.arange(1,6)/np.sqrt(2))\n",
    "print(np.percentile(samples['edepth'], sigmas*100)*1e6)\n",
    "print(10**(np.percentile(samples['log_edepth'], sigmas*100))*1e6)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ppm = 1e6\n",
    "edepth_mean = pm.summary(trace, var_names=varnames)['mean'].loc['edepth']\n",
    "edepth_sd = pm.summary(trace, var_names=varnames)['sd'].loc['edepth']\n",
    "\n",
    "edepth_mod = np.sign(edepth_mean)*np.sqrt(edepth_mean.__abs__())\n",
    "unc_edepth = abs(2*edepth_sd*edepth_mod)\n",
    "print(edepth_mod*ppm, unc_edepth*ppm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AXl22v6jp_2i"
   },
   "source": [
    "Now we can plot the simulated data and the maximum a posteriori model to make sure that our initialization looks ok."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y9xbZ7Atp_2l"
   },
   "source": [
    "## Sampling\n",
    "\n",
    "Now, let's sample from the posterior defined by this model.\n",
    "As usual, there are strong covariances between some of the parameters so we'll use :func:`exoplanet.get_dense_nuts_step`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "beb1lgP_p_2l",
    "outputId": "ad0bf51d-16f0-4600-d929-d074d3f525d2"
   },
   "source": [
    "np.random.seed(42)\n",
    "with model:\n",
    "    trace = pm.sample(\n",
    "        tune=3000,\n",
    "        draws=3000,\n",
    "        start=map_soln,\n",
    "        chains=mp.cpu_count(),\n",
    "        step=xo.get_dense_nuts_step(target_accept=0.9),\n",
    "        cores=mp.cpu_count()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r6Sgztjkp_2n"
   },
   "source": [
    "After sampling, it's important that we assess convergence.\n",
    "We can do that using the `pymc3.summary` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aper_sum_columns = planet.normed_photometry_df.drop(\n",
    "    ['xcenter', 'ycenter'], axis=1).columns\n",
    "aper_sum_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_ = fine_grain_mcmcs_w_xcenterfit[fine_min_snr_colname]['trace']\n",
    "dir(trace_)\n",
    "trace_.report._gelman_rubin.values()\n",
    "dir(trace_.report)\n",
    "trace_.report._run_convergence_checks??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "colab_type": "code",
    "id": "OHVfu27Ip_2o",
    "outputId": "09042a5e-52a6-479b-806a-040551f27b4a"
   },
   "outputs": [],
   "source": [
    "# fine_grain_mcmcs_w_xcenterfit[fine_min_snr_colname]['map_soln']\n",
    "edepths = []\n",
    "means = []\n",
    "slopes = []\n",
    "slopes_xcenter = []\n",
    "\n",
    "edepths_unc = []\n",
    "means_unc = []\n",
    "slopes_unc = []\n",
    "slopes_xcenter_unc = []\n",
    "\n",
    "mesh_widths = []\n",
    "mesh_heights = []\n",
    "\n",
    "for colname in tqdm(aper_sum_columns):\n",
    "    aper_width_, aper_height_ = np.int32(colname.split('_')[-1].split('x'))\n",
    "    mesh_widths.append(aper_width_)\n",
    "    mesh_heights.append(aper_height_)\n",
    "\n",
    "    # Load Summary from Colname\n",
    "    summary_df = pm.summary(fine_grain_mcmcs_w_xcenterfit[colname]['trace'], varnames=varnames)\n",
    "\n",
    "    # Store mean values\n",
    "    edepths.append(summary_df['mean'].loc['edepth'])\n",
    "    means.append(summary_df['mean'].loc['mean'])\n",
    "    slopes.append(summary_df['mean'].loc['slope'])\n",
    "    slopes_xcenter.append(summary_df['mean'].loc['slope_xcenter'])\n",
    "\n",
    "    # Store uncertainties\n",
    "    edepths_unc.append(summary_df['sd'].loc['edepth'])\n",
    "    means_unc.append(summary_df['sd'].loc['mean'])\n",
    "    slopes_unc.append(summary_df['sd'].loc['slope'])\n",
    "    slopes_xcenter_unc.append(summary_df['sd'].loc['slope_xcenter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "colab_type": "code",
    "id": "OHVfu27Ip_2o",
    "outputId": "09042a5e-52a6-479b-806a-040551f27b4a"
   },
   "outputs": [],
   "source": [
    "df_columns = [\"aper_width\", \"aper_height\", \"edepth\", \"mean\", \"slope\", \"slope_xcenter\"]\n",
    "means_df = pd.DataFrame(np.transpose([mesh_widths, mesh_heights, edepths, means, slopes, slopes_xcenter]), \n",
    "                        columns=df_columns)\n",
    "uncs_df = pd.DataFrame(np.transpose([mesh_widths, mesh_heights, edepths_unc, means_unc, slopes_unc, slopes_xcenter_unc]), \n",
    "                        columns=df_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mesh_widths_sorted = np.argsort(mesh_widths)\n",
    "# mesh_heights_sorted = np.argsort(mesh_heights)\n",
    "plt.plot(means_df['aper_width'], (means_df['edepth'] / uncs_df['edepth']), '.')\n",
    "plt.plot(means_df['aper_height'], (means_df['edepth'] / uncs_df['edepth']),'.')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(means_df['aper_height']*means_df['aper_width'], (means_df['edepth'] / uncs_df['edepth']),'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_widths_sorted = np.argsort(mesh_widths)\n",
    "mesh_heights_sorted = np.argsort(mesh_heights)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(means_df['aper_width'], means_df['mean'],'.')\n",
    "plt.plot(means_df['aper_height'], means_df['mean'],'.')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(means_df['aper_height']*means_df['aper_width'], means_df['mean'],'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ka3b7ucAp_2q"
   },
   "source": [
    "That looks pretty good!\n",
    "Fitting this without *exoplanet* would have taken a lot more patience.\n",
    "\n",
    "Now we can also look at the [corner plot](https://corner.readthedocs.io) of some of that parameters of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygtc\n",
    "import corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = fine_grain_mcmcs_w_xcenterfit[fine_min_snr_colname]['trace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lightcurves_fwd = trace['light_curves_fwd'].shape[0]\n",
    "light_curves_fwd = trace['light_curves_fwd'].reshape(trace['light_curves_fwd'].shape[:2])#trace['mean_fwd'][:,None]\n",
    "\n",
    "n_lightcurves_rev = trace['light_curves_rev'].shape[0]\n",
    "light_curves_rev = trace['light_curves_rev'].reshape(trace['light_curves_rev'].shape[:2])#trace['mean_rev'][:,None]\n",
    "\n",
    "for k in np.random.choice(np.arange(n_lightcurves_fwd), size=100):\n",
    "    plt.plot(t[idx_fwd], light_curves_fwd[k], '.', color='C0', alpha=0.25)\n",
    "\n",
    "for k in np.random.choice(np.arange(n_lightcurves_rev), size=100):\n",
    "    plt.plot(t[idx_rev], light_curves_rev[k], '.', color='C1', alpha=0.25)\n",
    "\n",
    "plt.ylim(-1e-5, 1e-6);\n",
    "plt.xlim(t0_guess - 0.1, t0_guess + 0.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 983
    },
    "colab_type": "code",
    "id": "jfCeokGEp_2q",
    "outputId": "7bf78c3f-897d-4f23-cc05-b80a9c1fbcd6"
   },
   "outputs": [],
   "source": [
    "for colname in tqdm(aper_sum_columns):\n",
    "    trace = fine_grain_mcmcs_w_xcenterfit[colname]['trace']\n",
    "    \n",
    "    samples = pm.trace_to_dataframe(trace, varnames=varnames)\n",
    "    truth = [0.0, 1.0, 1.0, 0.0]\n",
    "    corner.corner(samples, truths=truth, labels=varnames);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MpMLcJQOp_2s"
   },
   "source": [
    "## Phase plots\n",
    "\n",
    "Like in the radial velocity tutorial (:ref:`rv`), we can make plots of the model predictions for each planet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_fit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "colab_type": "code",
    "id": "WjqqqQGIp_2t",
    "outputId": "23dd3dec-e1ba-4464-b4d4-997746b357cd"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "# Get the posterior median orbital parameters\n",
    "p = period\n",
    "# t0 = np.median(trace[\"t0\"])\n",
    "\n",
    "# Plot the folded data\n",
    "line_fit =  + trace['slope_xcenter'] + trace['slope']\n",
    "line_fit = slope * (t-t0_guess) + mean + slope * (xcenters-np.median(xcenters))\n",
    "\n",
    "plt.errorbar(times[idx_fwd] - t0, (data - line_fit + 1.0)[idx_fwd], yerr=yerr[idx_fwd], fmt=\".\", color='C0', label=\"fwd data\", zorder=-1000)\n",
    "plt.errorbar(times[idx_rev] - t0, (data - line_fit + 1.0)[idx_rev], yerr=yerr[idx_rev], fmt=\".\", color='C3', label=\"rev data\", zorder=-1000)\n",
    "\n",
    "# Plot the folded model\n",
    "preds_fwd = trace[\"light_curves\"][:,:,0]\n",
    "# preds_rev = trace[\"light_curves\"][:,:,0] + trace[\"mean\"][:, None]\n",
    "pred_fwd = np.median(preds_fwd, axis=0)\n",
    "# pred_rev = np.median(preds_rev, axis=0)\n",
    "\n",
    "\n",
    "plt.plot(times - t0, pred_fwd, color=\"C1\", label=\"model\", zorder=10)\n",
    "# plt.plot(t[idx_rev] - t0, pred_rev, color=\"C2\", label=\"model\", zorder=10)\n",
    "plt.axhline(1.0, ls='--', color='k')\n",
    "\n",
    "# Annotate the plot with the planet's period\n",
    "txt = f\"Eclipse Depth = {np.mean(trace['edepth']*1e6):.0f}\"\n",
    "txt += f\" +/- {np.std(trace['edepth']*1e6):.0f} ppm\"\n",
    "\n",
    "plt.annotate(\n",
    "    txt,\n",
    "    (0, 0),\n",
    "    xycoords=\"axes fraction\",\n",
    "    xytext=(5, 5),\n",
    "    textcoords=\"offset points\",\n",
    "    ha=\"left\",\n",
    "    va=\"bottom\",\n",
    "    fontsize=12,\n",
    ")\n",
    "\n",
    "add_traces = False\n",
    "if add_traces:\n",
    "    n_traces = 1000\n",
    "    \n",
    "    idx_rand = np.random.choice(np.arange(preds_fwd.shape[0]), size=n_traces, replace=False)\n",
    "    for pred_ in preds_fwd[idx_rand]:\n",
    "        plt.plot(times - t0, pred_, color=\"grey\", alpha=0.5, zorder=0)\n",
    "\n",
    "    # idx_rand = np.random.choice(np.arange(preds_fwd.shape[0]), size=n_traces, replace=False)\n",
    "    # for pred_ in preds_rev[idx_rand]:\n",
    "    #     plt.plot(t[idx_rev] - t0, pred_, color=\"grey\", alpha=0.5, zorder=0)\n",
    "\n",
    "plt.legend(fontsize=10, loc=4)\n",
    "plt.xlim((times - t0).min(), (times - t0).max())\n",
    "plt.xlabel(\"Time Since Eclipse [days]\")\n",
    "plt.ylabel(\"Relative Flux\")\n",
    "plt.title(\"PlanetName Eclipse\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_DCj2Oh6p_2v"
   },
   "source": [
    "## Citations\n",
    "\n",
    "As described in the :ref:`citation` tutorial, we can use :func:`exoplanet.citations.get_citations_for_model` to construct an acknowledgement and BibTeX listing that includes the relevant citations for this model.\n",
    "This is especially important here because we have used quite a few model components that should be cited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "hn6rJIQVp_2v",
    "outputId": "3f1e259e-984c-4934-d986-b9a44cf1ba70"
   },
   "outputs": [],
   "source": [
    "with model:\n",
    "    txt, bib = xo.citations.get_citations_for_model()\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "qOIgfN87p_2x",
    "outputId": "69589eb5-c895-4753-dfc9-8aa3a043a989"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\".join(bib.splitlines()[:10]) + \"\\n...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v8yMkKOXp_2z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "planet name exoplanet transit tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
